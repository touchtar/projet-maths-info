{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet numérique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interprétation physique.\n",
    "\n",
    "$x_1 = Population~de~proies\\\\x_2 = Population~de~prédateurs\\\\\\alpha = Taux~de~reproduction~des~proies\\\\\\beta x_2 = Taux~de~destruction~des~proies~en~fonction~du~nombre~de~prédateurs\\\\\\beta = Taux~de~destruction~des~proies~par~prédateur\\\\\\gamma = Taux~de~mortalité~naturelle~des~prédateurs\\\\\\delta x_1 = Taux~de~reproduction~des~prédateurs~en~fonction~du~nombre~de~proies~disponibles\\\\\\delta = Taux~de~reproduction~des~prédateurs~par~proie~disponible$\n",
    "\n",
    "### Recherche des points d'équilibre.\n",
    "\n",
    "On a: $f:\\mathbb{R}_+\\times\\mathbb{R}_+\\longrightarrow\\mathbb{R}\\times\\mathbb{R}\\\\f(x = (x_1,x_2)) = (x_1(\\alpha-\\beta x_2), -x_2(\\gamma-\\delta x_1))$\n",
    "\n",
    "$f(x_1,x_2) = (0,0)\\iff \\left\\{ \\begin{array}{ll} x_1(\\alpha-\\beta x_2) = 0~(1) \\\\ x_2(\\gamma-\\delta x_1) = 0~(2) \\end{array} \\right.$\n",
    "\n",
    "$\\delta(1)+\\beta(2)\\Rightarrow\\alpha\\delta x_1-\\delta\\beta x_1 x_2-\\gamma\\beta x_2+\\delta\\beta x_1 x_2 = 0\\iff\\alpha\\delta x_1-\\gamma\\beta x_2 = 0 \\Rightarrow\\left\\{ \\begin{array}{ll} x_1=0~et~x_2=0 \\\\ x_1=\\frac{\\gamma}{\\delta}~et~x_2=\\frac{\\alpha}{\\beta} \\end{array} \\right.$\n",
    "\n",
    "Il existe donc deux points d'équilibre:\n",
    "$(0,0)~et~\\overline{x}=(\\frac{\\gamma}{\\delta},\\frac{\\alpha}{\\beta})$\n",
    "\n",
    "Calculons la Jacobienne de f:\n",
    "\n",
    "$J_f(x_1,x_2)=\\begin{pmatrix} \\alpha-\\beta x_2 & -\\beta x_1 \\\\ \\delta x_2 & \\delta x_1-\\gamma\\end{pmatrix}$\n",
    "\n",
    "$J_f(0,0) = \\begin{pmatrix} \\alpha & 0 \\\\ 0 & -\\gamma\\end{pmatrix}=A\\Rightarrow\\left\\{ \\begin{array}{ll} tr(A) = \\alpha-\\gamma \\\\ det(A) = -\\alpha\\gamma<0\\Rightarrow Point~instable. \\end{array} \\right.$\n",
    "\n",
    "$J_f(\\overline{x}) = \\begin{pmatrix} 0 & -\\frac{\\beta\\gamma}{\\delta} \\\\ \\frac{\\delta\\alpha}{\\beta} & 0\\end{pmatrix}=A\\Rightarrow\\left\\{ \\begin{array}{ll} tr(A) = 0 \\\\ det(A) = \\alpha\\gamma>0\\end{array} \\right.$\n",
    "\n",
    "On ne peut donc pas conclure quant à la stabilité du point $\\overline{x}$ ici car $tr(A)=0$. Le linéarisé ne suffit pas, il faudra avoir recours à la carctérisation de Lyapunov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd\n",
    "import autograd.numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global alpha\n",
    "alpha = 1.5\n",
    "global beta\n",
    "beta = 1.5\n",
    "global delta\n",
    "delta = 1.5\n",
    "global gamma\n",
    "gamma = 1.5\n",
    "\n",
    "\n",
    "def f(x1 ,x2):\n",
    "    return np.array([x1*(alpha-beta*x2), -x2*(gamma-delta*x1)])\n",
    "\n",
    "\n",
    "# Champ de vecteurs\n",
    "def champ(fct):\n",
    "    x = np.linspace(0, 5, 20)\n",
    "    y = np.linspace(0, 5, 20)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    R = f(X, Y)\n",
    "    plt.quiver(X, Y, R[0], R[1], scale = 50)\n",
    "    plt.title(\"Champ de vecteurs des équations de Lotka-Volterra\")\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "# Portrait de phase\n",
    "def phase(fct):\n",
    "    x = np.linspace(0, 5, 20)\n",
    "    y = np.linspace(0, 5, 20)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = X, Y\n",
    "    R = f(X, Y)\n",
    "    plt.streamplot(X, Y, R[0], R[1])\n",
    "    plt.title(\"Portrait de phase des équations de Lotka-Volterra\")\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "champ(f)\n",
    "phase(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les solutions semblent suivre chacune un cycle stable, avec un point d'équilibre au centre, ici en (1,1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction $f$ étant l'assemblage de fonctions linéaires de $\\mathbb{R}_+$ dans $\\mathbb{R}$, qui sont $C^\\infty$, elle est $C^\\infty$ donc $C^1$. D'après le Théorème de Cauchy-Lipschitz, $\\forall(t_0,x_0)\\in\\mathbb{R}\\times(\\mathbb{R}_+\\times\\mathbb{R}_+)$, il existe une unique solution maximale $x:\\mathbb{R}\\Rightarrow\\mathbb{R}^2$ dans $S_f(t_0,x_0)$.\n",
    "\n",
    "Il suffit alors de montrer que les droites $\\{0\\}~\\times~]0,+\\infty[$ et $]0,+\\infty[~\\times~\\{0\\}$ sont des trajectoires possibles de notre système.\n",
    "\n",
    "$x_{1_0} = 0\\Rightarrow\\dot{x_1}=0\\Rightarrow x_1(t)=0~~\\forall t\\in\\mathbb{R}\\Rightarrow\\dot{x_2}=-\\gamma x_2\\iff x_2(t) = x_{2_0}e^{-\\gamma t}\\underset{t\\to +\\infty}{\\rightarrow}0$\n",
    "\n",
    "La droite $\\{0\\}~\\times~]0,+x_{2_0}[$ est une trajectoire $\\forall x_{2_0}\\in\\mathbb{R}_{>0}$\n",
    "\n",
    "$x_{2_0} = 0\\Rightarrow\\dot{x_2}=0\\Rightarrow x_2(t)=0~~\\forall t\\in\\mathbb{R}\\Rightarrow\\dot{x_1}=\\alpha x_1\\iff x_1(t) = x_{1_0}e^{\\alpha t}\\underset{t\\to +\\infty}{\\rightarrow}0$\n",
    "\n",
    "La droite $[x_{1_0},+\\infty[~\\times~\\{0\\}$ est une trajectoire $\\forall x_{1_0}\\in\\mathbb{R}_{>0}$\n",
    "\n",
    "Ainsi quelle que soit la trajectoire initialisée dans $\\mathbb{R}_{>0}\\times\\mathbb{R}_{>0}$ et qui sort de ce domaine, on peut trouver une trajectoire accessible au système qui la croise. Ce genre de trajectoire sortante n'existe donc pas et n'importe quelle solution initialisée dans $\\mathbb{R}_{>0}\\times\\mathbb{R}_{>0}$ y reste $\\forall t\\in\\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (Ancienne version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H(x_1,x_2)=\\delta x_1-\\gamma ln(x_1)+\\beta x_2-\\alpha ln(x_2)$\n",
    "\n",
    "$\\nabla H(x_1,x_2)=\\begin{pmatrix} \\delta-\\frac{\\gamma}{x_1}\\\\\\beta-\\frac{\\alpha}{x_2}\\end{pmatrix}\\Rightarrow \\langle\\nabla H(x_1,x_2),f(x_1,x_2)\\rangle=(\\delta-\\frac{\\gamma}{x_1})x_1(\\alpha-\\beta x_2)+(\\beta-\\frac{\\alpha}{x_2})x_2(\\delta x_1 -\\gamma)=0~~\\forall x\\in\\mathbb{R}_{>0}\\times\\mathbb{R}_{>0}$\n",
    "\n",
    "L'orthogonalité de $\\nabla H$ et $f$ étant définie sur $\\mathbb{R}_{>0}\\times\\mathbb{R}_{>0}$, f ne peut pas exploser en temps fini quelle que soit la solution dans $\\mathbb{R}_{>0}\\times\\mathbb{R}_{>0}$ et donc toute solution maximale initialisée dans $\\mathbb{R}_{>0}\\times\\mathbb{R}_{>0}$ est définie sur $\\mathbb{R}$.\n",
    "\n",
    "On a en particulier $\\nabla H(\\overline{x})=\\begin{pmatrix} \\delta-\\frac{\\gamma\\delta}{\\delta}\\\\\\beta-\\frac{\\alpha\\beta}{\\alpha}\\end{pmatrix}=0$\n",
    "\n",
    "Pour démontrer la stabilité de $\\overline{x}$, nous allons avoir besoin de la caractérisation de Lyapunov. Il nous faut donc une fonction $V:W\\to\\mathbb{R}_{\\geq 0}$ (avec $W$ voisinage de $\\overline{x}$) continûment différentiable telle que:\n",
    "\n",
    "$V(x)>0~~\\forall x\\in W\\backslash\\{\\overline{x}\\}$ et $V(\\overline{x})=0$ et $\\langle\\nabla V(x),f(x)\\rangle\\leq0~~\\forall x\\in W$\n",
    "\n",
    "Etudions le signe de $H(x_1,x_2)$ sur $\\mathbb{R}_{>0}\\times\\mathbb{R}_{>0}$. Pour cela, étudions d'abord celui de $g_1:x\\in\\mathbb{R}_{\\geq 0}\\mapsto\\delta x-\\gamma ln(x)$\n",
    "\n",
    "$g_1'(x)=\\delta-\\frac{\\gamma}{x}= 0 \\Rightarrow\\left\\{\n",
    "    \\begin{array}{ll}\n",
    "        g_1'(x)>0\\iff x>\\frac{\\gamma}{\\delta}\\\\\n",
    "        g_1'(x)<0\\iff x<\\frac{\\gamma}{\\delta}\\\\\n",
    "        g_1'(x)=0\\iff x=\\frac{\\gamma}{\\delta}\n",
    "    \\end{array}\n",
    "\\right.\\Rightarrow~Minimum~en~x=\\frac{\\gamma}{\\delta}\\\\g_1(\\frac{\\gamma}{\\delta})=\\gamma-\\gamma ln(\\frac{\\gamma}{\\delta})$\n",
    "\n",
    "On peut alors construire $h_1:x\\in\\mathbb{R}_{\\geq 0}\\mapsto g_1(x)-g_1(\\frac{\\gamma}{\\delta})$ et ainsi $h_1(x)$ est toujours positive et est nulle en $x=\\frac{\\gamma}{\\delta}$.\n",
    "\n",
    "On reproduit la même méthode avec la fonction $g_2:x\\in\\mathbb{R}_{\\geq 0}\\mapsto\\beta x-\\alpha ln(x)$ et l'on construit $h_2:x\\in\\mathbb{R}_{\\geq 0}\\mapsto g_2(x)-g_2(\\frac{\\alpha}{\\beta})$ toujours positive et nulle en $x=\\frac{\\alpha}{\\beta}$.\n",
    "\n",
    "Or $H(x_1,x_2)=g_1(x_1)+g_2(x_2)$ et l'on peut poser:\n",
    "\n",
    "$V:(x_1,x_2)\\mapsto H(x_1,x_2)-H(\\overline{x})=g_1(x_1)-g_1(\\frac{\\gamma}{\\delta})-(g_2(x_2)-g_2(\\frac{\\alpha}{\\beta}))$\n",
    "\n",
    "On a donc montré que $V(x)>0~~\\forall x\\in\\mathbb{R}_{>0}\\times\\mathbb{R}_{>0}\\backslash\\{\\overline{x}\\}$ et $V(\\overline{x})=0$. De plus, $\\langle\\nabla V(x),f(x)\\rangle=\\langle\\nabla H(x),f(x)\\rangle=0~~\\forall x\\in\\mathbb{R}_{>0}\\times\\mathbb{R}_{>0}$.\n",
    "\n",
    "Toutes ces propriétés de V étant vraies sur l'ouvert $\\mathbb{R}_{>0}\\times\\mathbb{R}_{>0}$, elles le sont aussi pour toute restriction de cet ouvert, donc pour tout voisinage $W$ de $x_0\\in\\mathbb{R}_{>0}\\times\\mathbb{R}_{>0}$. V(x) est fonction de Lyapunov de notre système et le point $\\overline{x}$ est stable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(x1, x2):\n",
    "    return delta*x1 - gamma*np.log(x1) + beta*x2 - alpha*np.log(x2)\n",
    "\n",
    "def display_contour(fct, levels):\n",
    "    # Les bornes commencent à 0.1 pour éviter les divergences du log en 0.\n",
    "    x = np.linspace(0.1, 5, 20)\n",
    "    y = np.linspace(0.1, 5, 20)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = fct(X, Y)\n",
    "    fig, ax = plt.subplots()\n",
    "    contour_set = plt.contour(\n",
    "        X, Y, Z, colors=\"grey\", linestyles=\"dashed\", \n",
    "        levels=levels \n",
    "    )\n",
    "    ax.clabel(contour_set)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"$x_1$\") \n",
    "    plt.ylabel(\"$x_2$\")\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.title(\"Courbes de niveau de H\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "display_contour(H, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_euler_explicit(f, x0, dt, t0, tf):\n",
    "    t = np.arange(t0, tf+dt, dt)\n",
    "    x = np.zeros(shape=(2,1), dtype=float)\n",
    "    x = np.column_stack([x, x0])\n",
    "    for i in t[:-1]:\n",
    "        new_x = np.array([x[0][-1], x[1][-1]]) + dt*f(x[0][-1], x[1][-1])\n",
    "        x = np.column_stack([x,new_x])\n",
    "    return t, np.array([x[0][1:],x[1][1:]]) \n",
    "\n",
    "\n",
    "def test_perfect(x0, dt, t0, tf):\n",
    "    t = np.arange(t0, tf, dt)\n",
    "    x = np.zeros(shape = (2,1), dtype = float)\n",
    "    x = np.column_stack([x, x0])\n",
    "    for i in t:\n",
    "        new_x = np.array([np.cos(i), np.sin(i)])\n",
    "        x = np.column_stack([x,new_x])\n",
    "    return t, np.array([x[0][1:],x[1][1:]])\n",
    "\n",
    "\n",
    "def f_test(x1, x2):\n",
    "    return np.array([-x2, x1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test d'Euler explicite sur une solution connue.\n",
    "time, result = solve_euler_explicit(f_test, np.array([1.0, 0.0]), 0.1, 0.0, 10.0)\n",
    "time_perfect, result_perfect = test_perfect(np.array([1.0, 0.0]), 0.1, 0.0, 10.0)\n",
    "plt.plot(result[0], result[1], 'x', label='Euler explicite')\n",
    "plt.plot(result_perfect[0], result_perfect[1], 'x', label='Solution parfaite')\n",
    "plt.legend()\n",
    "plt.xlabel(\"$x_1$\") \n",
    "plt.ylabel(\"$x_2$\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution de l'erreur et ordre du schéma Euler explicite.\n",
    "err_array = np.zeros(shape = (2,1), dtype=float)\n",
    "t_max = 10.0\n",
    "for i in range(3, 15):\n",
    "    # On teste la convergence sur un nombre de pas qui varie par puissances de 2 (choix arbitraire) \n",
    "    # sur l'equation différentielle du cercle.\n",
    "    n_steps =int(2**i)\n",
    "    delta_t = t_max/n_steps\n",
    "    # Résultat de Euler explicite.\n",
    "    result = solve_euler_explicit(f_test, np.array([1.0, 0.0]), delta_t, 0.0, t_max)[1]\n",
    "    # Solution parfaite.\n",
    "    result_perfect = test_perfect(np.array([1.0, 0.0]), delta_t, 0.0, t_max)[1]\n",
    "    # Calcul de l'erreur avec le dernier point obtenu\n",
    "    err = np.abs(np.linalg.norm(np.array([result[0][-1], result[1][-1]])-np.array([result_perfect[0][-1], result_perfect[1][-1]])))\n",
    "    # On met les erreurs calculées pour chaque pas de temps dans un array pour plotter ensuite.\n",
    "    err_array = np.column_stack([err_array, np.array([delta_t, err])])\n",
    "plt.plot(err_array[0][1:], err_array[1][1:], label='Explicite')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Taille du pas (échelle log)')\n",
    "plt.ylabel('Erreur (échelle log)')\n",
    "plt.title(\"Evolution de l'erreur pour Euler explicite\")\n",
    "plt.annotate('Pente de 1, ordre de la méthode', xy=(0.02, 0.1), xytext=(0.1, 0.05), \n",
    "             arrowprops = {'facecolor': 'red', 'shrink': 0.1, 'width': 0.1, 'headwidth': 5.0})\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euler explicite sur Lotka-Volterra.\n",
    "time, result = solve_euler_explicit(f, np.array([1.0, 3.0]), 0.01, 0.0, 10.0)\n",
    "plt.plot(result[0], result[1], '-', label='Explicite')\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.title('Euler explicite sur Lotka-Volterra en partant de (1,3).')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution de H en fonction du temps.\n",
    "H_result = H(result[0],result[1])\n",
    "plt.plot(time, H_result)\n",
    "plt.title('Evolution de H en fonction du temps')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate qu'en temps long, la trajectoire calculée via Euler explicite diverge lentement. Ce n'est pas le comportement qu'elle devrait avoir puisqu'elle est censée suivre la ligne de niveau de $H$ car $\\langle\\nabla H(x),f(x)\\rangle=0~~\\forall t\\in\\mathbb{R}$. Ce comportement est également remarquable sur le graphe de l'évolution de $H$, puisqu'elle est censée rester constante le long de n'importe quelle trajectoire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_euler_implicit(f, x0, dt, t0, tf):\n",
    "    t = np.arange(t0, tf+dt, dt)\n",
    "    x = np.zeros(shape=(2, 1), dtype=float)\n",
    "    x = np.column_stack([x, x0])\n",
    "    for i in t[:-1]:\n",
    "        new_x = np.array([x[0][-1], x[1][-1]]) + dt*f(x[0][-1], x[1][-1])\n",
    "        ant_x = new_x\n",
    "        next_x = new_x +dt*f(ant_x[0], ant_x[1])\n",
    "        # Le seuil choisi ici est arbitraire égal à 0,01.\n",
    "        while np.linalg.norm(next_x-ant_x)/np.linalg.norm(new_x) >= 0.01:\n",
    "            ant_x = next_x\n",
    "            next_x = new_x +dt*f(ant_x[0], ant_x[1])\n",
    "        x = np.column_stack([x, next_x])\n",
    "    return t, np.array([x[0][1:], x[1][1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test d'Euler implicite sur une solution connue.\n",
    "time, result = solve_euler_implicit(f_test, np.array([1.0, 0.0]), 0.1, 0.0, 10.0)\n",
    "time_perfect, result_perfect = test_perfect(np.array([1.0, 0.0]), 0.1, 0.0, 10.0)\n",
    "plt.plot(result[0], result[1], 'x', label='Euler implicite')\n",
    "plt.plot(result_perfect[0], result_perfect[1], 'x', label='Solution parfaite')\n",
    "plt.legend()\n",
    "plt.xlabel(\"$x_1$\") \n",
    "plt.ylabel(\"$x_2$\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution de l'erreur et ordre du schéma Euler implicite.\n",
    "err_array = np.zeros(shape = (2,1), dtype=float)\n",
    "err = 1000\n",
    "t_max = 10.0\n",
    "for i in range(10, 17):\n",
    "    n_steps =int(2**i)\n",
    "    delta_t = t_max/n_steps\n",
    "    result = solve_euler_implicit(f_test, np.array([1.0, 0.0]), delta_t, 0.0, t_max)[1]\n",
    "    for ix, iy in zip(result[0], result[1]):\n",
    "        norme = np.linalg.norm(np.array([ix, iy])-np.array([0.0, 1.0]))\n",
    "        if norme < err:\n",
    "            err = norme\n",
    "    err_array = np.column_stack([err_array, np.array([delta_t, err])])\n",
    "\n",
    "plt.plot(err_array[0][1:], err_array[1][1:], label='Implicite')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Taille du pas (échelle log)')\n",
    "plt.ylabel('Erreur (échelle log)')\n",
    "plt.title(\"Evolution de l'erreur pour Euler implicite\")\n",
    "plt.annotate('Pente de 1, ordre de la méthode', xy=(0.02, 0.1), xytext=(0.1, 0.05), arrowprops = {'facecolor': 'red', 'shrink': 0.1, 'width': 0.1, 'headwidth': 5.0})\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euler implicite sur Lotka-Volterra.\n",
    "time, result = solve_euler_implicit(f, np.array([1.0, 3.0]), 0.01, 0.0, 10.0)\n",
    "plt.plot(result[0], result[1], '-', label='Implicite')\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.title('Euler implicite sur Lotka-Volterra en partant de (1,3).')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution de H pour Euler implicite en fonction du temps.\n",
    "H_result = H(result[0],result[1])\n",
    "plt.plot(time, H_result)\n",
    "plt.title('Evolution de H en fonction du temps (implicite)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison Euler.\n",
    "time, result = solve_euler_implicit(f, np.array([1.0, 3.0]), 0.01, 0.0, 15.0)\n",
    "plt.plot(result[0], result[1], '-', label='Implicite')\n",
    "time, result = solve_euler_explicit(f, np.array([1.0, 3.0]), 0.01, 0.0, 15.0)\n",
    "plt.plot(result[0], result[1], '-', label='Explicite')\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.title('Euler explicite et Euler implicite sur Lotka-Volterra en partant de (1,3).')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit très clairement que la méthode implicite est bien plus stable que la méthode explicite. La variation de $H$ est plus faible et par escalier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $(x_1, x_2)$ est solution de $ \\left \\{ \\begin{matrix}\n",
    "\\dot{x_1} = x_1 \\left ( \\alpha - \\beta x_2 \\right ) \\\\\n",
    "\\dot{x_2} = - x_2 \\left ( \\gamma - \\delta x_1 \\right )\n",
    "\\end{matrix}\n",
    "\\right .$, on sait que la fonction $H$ est constante donc $H - H_0$ est toujours nul. Ainsi, on a bien $(x_1, x_2)$ solution de \n",
    "$ \\left \\{ \\begin{matrix}\n",
    "\\dot{x_1} = x_1 \\left ( \\alpha - \\beta x_2 \\right ) - u_1(x_1, x_2) \\left ( H(x_1, x_2) - H_0 \\right ) \\\\\n",
    "\\dot{x_2} = - x_2 \\left ( \\gamma - \\delta x_1 \\right ) - u_2(x_1, x_2) \\left ( H(x_1, x_2) - H_0 \\right )\n",
    "\\end{matrix}\n",
    "\\right .$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Les deux systèmes \n",
    "$ \\left \\{ \\begin{matrix}\n",
    "\\dot{x_1} = x_1 \\left ( \\alpha - \\beta x_2 \\right ) - u_1(x_1, x_2) \\left ( H(x_1, x_2) - H_0 \\right ) \\\\\n",
    "\\dot{x_2} = - x_2 \\left ( \\gamma - \\delta x_1 \\right ) - u_2(x_1, x_2) \\left ( H(x_1, x_2) - H_0 \\right )\n",
    "\\end{matrix}\n",
    "\\right .$ \n",
    "et \n",
    "$ \\left \\{ \\begin{matrix}\n",
    "\\dot{x_1} = x_1 \\left ( \\alpha - \\beta x_2 \\right ) \\\\\n",
    "\\dot{x_2} = - x_2 \\left ( \\gamma - \\delta x_1 \\right )\n",
    "\\end{matrix}\n",
    "\\right .$ \n",
    "sont uniquement composés de fonctions continûment différentiables donc la solution de chaque système est unique pour une condition initiale donnée et égale à la solution maximale. \n",
    "\n",
    "\n",
    "Si on part de la condition initale $t = 0$, notons $X_0$ la solution du système $ \\left \\{ \\begin{matrix}\n",
    "\\dot{x_1} = x_1 \\left ( \\alpha - \\beta x_2 \\right ) - u_1(x_1, x_2) \\left ( H(x_1, x_2) - H_0 \\right ) \\\\\n",
    "\\dot{x_2} = - x_2 \\left ( \\gamma - \\delta x_1 \\right ) - u_2(x_1, x_2) \\left ( H(x_1, x_2) - H_0 \\right )\n",
    "\\end{matrix}\n",
    "\\right .$. On sait que en $t = 0$, cette solution est égale à la solution du système de Lotka-Voltera en $t = 0$, notée $X_1$. \n",
    "\n",
    "\n",
    "Comme les solutions $X_0$ et $X_1$ sont uniques et que l'on sait que $X_1$ est aussi solution du système, on a bien $X_0 = X_1$ \n",
    "$ \\left \\{ \\begin{matrix}\n",
    "\\dot{x_1} = x_1 \\left ( \\alpha - \\beta x_2 \\right ) - u_1(x_1, x_2) \\left ( H(x_1, x_2) - H_0 \\right ) \\\\\n",
    "\\dot{x_2} = - x_2 \\left ( \\gamma - \\delta x_1 \\right ) - u_2(x_1, x_2) \\left ( H(x_1, x_2) - H_0 \\right )\n",
    "\\end{matrix}\n",
    "\\right .$, on a bien $X_0 = X_1$ ce qui prouve l'équivalence des solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a déjà calculé la dérivée de $H$ par rapport à $(x_1, x_2)$ : \n",
    "$\\nabla H(x_1,x_2)= \\begin{pmatrix} \n",
    "\\delta-\\frac{\\gamma}{x_1} \\\\\n",
    "\\beta - \\frac{\\alpha}{x_2}\n",
    "\\end{pmatrix}$\n",
    "\n",
    "On a donc \n",
    "$\\left \\| \\nabla H(x_1, x_2) \\right \\| ^2 = (\\delta - \\frac{\\gamma}{x_1})^2 + (\\beta - \\frac{\\alpha}{x_2})^2$\n",
    "\n",
    "Calculons la dérivée de $H-H_0$ par rapport au temps:\n",
    "\n",
    "$\\frac{d}{dt}(H - H_0) = \\left ( \\delta - \\frac{\\gamma}{x_1} \\right ) \\dot{x_1} + \\left ( \\beta - \\frac{\\alpha}{x_2} \\right ) \\dot{x_2}$\n",
    "\n",
    "$ = \\left ( \\delta - \\frac{\\gamma}{x_1} \\right ) \\left ( \\alpha - \\beta x_2 \\right ) x_1 - \\left ( \\beta - \\frac{\\alpha}{x_2} \\right ) \\left ( \\gamma - \\delta x_1 \\right )x_2 - \\left [ \\left ( \\delta - \\frac{\\gamma}{x_1} \\right ) u_1 + \\left ( \\beta - \\frac{\\alpha}{x_2} \\right ) u_2 \\right ] \\left ( H - H_0 \\right ) $\n",
    "\n",
    "Si l'on choisit $u$ colinéaire à $\\nabla H$, avec un facteur de colinéarité $k$, on obtient bien \n",
    "$\\frac{d}{dt}(H(x(t)) - H_0) = -k \\left \\| \\nabla H(x_1, x_2) \\right \\| ^2 \\left ( H(x(t)) - H_0 \\right )$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x$ reste à une distance strictement positive de $\\overline{x}$ donc on sait que $\\left \\| \\nabla H \\right \\| ^2 > 0$  et que $H(x(t)) - H_0$ reste de signe constant. On peut donc trouver $c$ et $C$ strictement positifs tel que $\\forall t$ $ C \\geq \\left \\| \\nabla H(x(t)) \\right \\| ^2 \\geq c$. On a alors :\n",
    "$-k C \\left ( H(x(t)) - H_0 \\right ) \\leq \\frac{d}{dt}(H(x(t)) - H_0) \\leq -k c \\left ( H(x(t)) - H_0 \\right )$. \n",
    "Par positivité de l'intégrale, on peut montrer que $e^{-k C t} \\leq H(x(t)) - H_0 \\leq e^{-k c t}$. $H(x(t))$ converge donc bien exponentiellement vers $H_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour assurer la stabilité de $H$ lors de l'implémentation du schéma d'Euler, il suffit d'utiliser le système : \n",
    "$ \\left \\{ \\begin{matrix}\n",
    "\\dot{x_1} = x_1 \\left ( \\alpha - \\beta x_2 \\right ) - u_1(x_1, x_2) \\left ( H(x_1, x_2) - H_0 \\right ) \\\\\n",
    "\\dot{x_2} = - x_2 \\left ( \\gamma - \\delta x_1 \\right ) - u_2(x_1, x_2) \\left ( H(x_1, x_2) - H_0 \\right )\n",
    "\\end{matrix}\n",
    "\\right .$ \n",
    "\n",
    "avec $u = k~\\nabla{H}$.\n",
    "\n",
    "Le rôle de k est de faire converger $H$ vers $H_0$ le plus rapidement possible, cependant, on ne peut pas le choisir arbitrairement grand. \n",
    "En effet dans le schéma d'Euler, on aura au premier ordre en utilisant $\\frac{d}{dt}(H(x) - H_0) = -k \\left \\| \\nabla H(x) \\right \\| ^2 \\left ( H(x) - H_0 \\right )$ : \n",
    "\n",
    "$H(x^{j+1}) - H_0 = \\left( 1 - k \\left \\| \\nabla H(x^j) \\right \\| ^2 dt \\right) \\left( H(x^j) - H_0 \\right)$.\n",
    "\n",
    "Or on a vu que $H$ converge vers $H_0$ exponentiellement, donc la différence $H - H_0$ a un signe constant. Si on choisit un pas de temps $dt$ trop petit ou un $k$ trop grand, tel que $1 - k \\left \\| \\nabla H(x_1, x_2) \\right \\| ^2 dt < 0$, le signe de la différence changera à chaque itération."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
